\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{url}
\usepackage{float}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=blue,
    linkcolor=blue,
    citecolor=blue
}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{IEEE-CIS Fraud Detection Challenge \\
    \large\textit{Comparative Study of SVM and Decision Tree Binary Classification}
}

\author{
    \IEEEauthorblockN{Khashayar Zardoui}
    \IEEEauthorblockA{\textit{Dept. Computer Science \& Software Engineering} \\
    \textit{Concordia University}\\
    Montreal, Canada \\
    khashayar.zardoui@mail.concordia.ca}
    {\footnotesize ID: 40052568}
    \and
    \IEEEauthorblockN{Paolo Junior Angeloni}
    \IEEEauthorblockA{\textit{Dept. Computer Science \& Software Engineering} \\
    \textit{Concordia University}\\
    Montreal, Canada \\
    p\_ange@live.concordia.ca}
    {\footnotesize ID: 25976944}
}

\pagestyle{plain}
\maketitle
\begin{abstract}
The objective of this project was to develop a machine learning pipeline capable of identifying fraudulent credit card transactions within the IEEE-CIS Fraud Detection dataset. The primary challenge was the extreme class imbalance (approx. 3.5\% fraud vs. 96.5\% legitimate), requiring models that prioritize Precision (minimizing customer friction via false alarms) while maintaining high Recall (capturing actual fraud).
\end{abstract}

\section{The Fraud-Detection Pipeline}
    We implemented a robust data processing pipeline involving missing value imputation, label encoding for categorical variables, and standard scaling. To address the computational challenges of the large dataset (590k+ entries), we utilized Principal Component Analysis (PCA) for dimensionality reduction on linear models. We evaluated three distinct classification architectures:
    \begin{enumerate}
        \item Linear Support Vector Machine (LinearSVC): A baseline linear classifier utilizing the Primal solver and PCA
        \item Decision Tree: A non-linear, rules-based classifier tuned for depth and split criteria
        \item XGBoost: An advanced gradient-boosting ensemble method utilizing histogram-based optimization
    \end{enumerate}
    \begin{enumerate}
        \item Data loading and exploration (EDA)
        \item Removal, Imputation, Label Encoding and Scaling
        \item Model training and performance assessment
    \end{enumerate}

\section{Exploratory Data Analysis}
    \subsection{Data Structure Inspection}
        \begin{enumerate}
            \item \par
                Before any data transformation, we observed the \texttt{train} and \texttt{test} datasets had a mixture of \texttt{float64}, \texttt{int64} and \texttt{object} types
            \item missing values \par
                description goes here...
            \item target balance \par
                description goes here...
        \end{enumerate}
\subsection{Statistical Summary \& Visualizations}
        \begin{figure}[H]
            \centering
            % \includegraphics[width=0.48\textwidth]{throughput_bufferChart.png}
            \caption{some image here}
            % \label{fig:some}
        \end{figure}
        \begin{table}[H]
            \centering
            \caption{some stats...}
            \begin{tabular}{|l|c|}
            \hline
            \textbf{Metric } & \textbf{Value} \\
            \hline
            one & ... \\
            two (\%) & ... \\
            three & ... \\
            four & ... \\
            \hline
            \end{tabular}
            % \label{tab:first_stats_resnet18}
        \end{table}
\subsection{Findings \& Hypotheses}
    ...
    \par\vspace{1em}
    ...

\section{Data Pre-Processing \& Cleaning}
\subsection{Imputation \& Removal}
        \begin{enumerate}
            \item ...
            \item ...
            \item ...
        \end{enumerate}
    \subsection{Normalize \& Scale Features}
        \begin{enumerate}
            \item ...
            \item ...
            \item ...
        \end{enumerate}
    \subsection{Encoding Categorical Features}
        \begin{enumerate}
            \item ...
            \item ...
            \item ...
        \end{enumerate}

\section{Models}
    \text{intro to the models used}

    \subsection{Support Vector Machine (SVM) Classifier}
    Due to the size of the dataset (590,000+ samples), a standard SVM with a non-linear kernel ($O(n^3)$) was computationally infeasible. We opted for a LinearSVC ($O(n)$) to utilize the entire training set. To satisfy the hyperparameter tuning requirement2, we tuned the Regularization parameter (C) and the Loss function (Hinge vs. Squared Hinge) instead of the kernel.
    Additionally, we applied Principal Component Analysis (PCA) to the SVM input to reduce dimensionality, which resolved convergence issues and significantly improved training speed.

    experiment hyperparameters (C, gamma, kernel etc)
    
    cross-validation and validation splits to evaluate performance
        
    results using different hyperparameters
        
    training and test metrics: confusion matrix, precision, recall, F1-score, and accuracy

    \subsection{Decision Tree Classifier}
        \text{experiment hyperparameters (max depth, min samples split, criterion)}
        \text{cross-validation and validation splits to evaluate performance}
        \text{results using different hyperparameters}
        \text{training and test metrics: confusion matrix, precision, recall, F1-score, and accuracy}
        \par
            The Decision Tree model demonstrated signs of mild overfitting. While it achieved a high F1-score of 0.68 on the training set, this dropped to 0.57 on the validation set. Specifically, the Precision for fraud detection fell from 92\% (training) to 77\% (validation), indicating that some of the decision rules learned were specific to the training noise and did not generalize well. Furthermore, the Recall remained low in both sets (0.53 training vs. 0.45 validation), suggesting that a single decision tree lacks the complexity required to capture the full variety of fraudulent patterns in this dataset.

    \subsection{XGBoost Classifier}
        \par
        \par
            The XGBoost classifier proved to be the superior model. While the Decision Tree suffered from overfitting (high variance), XGBoost demonstrated robust generalization.
            
            On the Validation set, XGBoost achieved a Precision of 0.93, meaning it generated very few false positives (false alarms), which is critical for maintaining user trust. Simultaneously, it achieved a Recall of 0.56, capturing the majority of fraud instances. The F1-Score of 0.70 (Validation) significantly outperforms the Decision Tree (0.57) and indicates that the Gradient Boosting method successfully captured complex, non-linear relationships that the simpler models missed.

\section{Model Comparison}
    \paragraph{discuss similarities \& differences. use table}    
    \begin{table}[H]
            \centering
            \caption{some stats...}
            \begin{tabular}{|l|c|c|}
            \hline
            \textbf{Metric } & \textbf{SVM} & \textbf{Decision Tree} \\
            \hline
            one & ... & ... \\
            two (\%) & ... & ... \\
            three & ... & ... \\
            four & ... & ... \\
            \hline
            \end{tabular}
            % \label{tab:first_stats_resnet18}
    \end{table}
    \par
    The LinearSVC provided a baseline AUC of 0.815, but struggled with convergence times and lacked the complexity to model non-linear fraud patterns.

    The Decision Tree achieved a higher AUC of 0.848, but exhibited signs of overfitting (high training accuracy vs. lower validation precision), confirming that a single tree has high variance.

    XGBoost emerged as the vastly superior model, achieving an AUC-ROC of 0.963 and an F1-Score of 0.70. It successfully balanced a high Precision (93\%) with a Recall of 56\%, significantly outperforming the other models in identifying fraud without disrupting legitimate users.

\par\vspace{1em}
\section*{Acknowledgment}
We would like to thank Professor Arash Azarfar and Firat Oncel for their guidance and support throughout this project. Large Language Models, like Google's Gemini were used in an educational context to further understand the resources for this research.

\begin{thebibliography}{00}
    \bibitem{b1} Numpy, ``Numpy API Documentation,'' [Online]. Available: \url{https://numpy.org/doc/stable/}. [Accessed: Nov. 25, 2025].
    \bibitem{b2} matplotlib, ``Matplotlib API Documentation,'' [Online]. Available: \url{https://matplotlib.org/stable/index.html}. [Accessed: Nov. 25, 2025].
    \bibitem{b3} pandas, ``pandas API Documentation,'' [Online]. Available: \url{https://pandas.pydata.org/docs/}. [Accessed: Nov. 26, 2025].
    \bibitem{b4} seaborn, ``seaborn API Documentation,'' [Online]. Available: \url{https://seaborn.pydata.org/api.html}. [Accessed: Nov. 26, 2025].
    \bibitem{b5} data preprocessing, ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/preprocessing.html}. [Accessed: Nov. 28, 2025].
    \bibitem{b6} data imputation, ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/impute.html}. [Accessed: Nov. 28, 2025].
    \bibitem{b7} label encoding, ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/preprocessing_targets.html#label-encoding}. [Accessed: Nov. 28, 2025].
    \bibitem{b8} hyperparameter tuning using GridSearchCV, ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/grid_search.html#grid-search}. [Accessed: Nov. 30, 2025].
    \bibitem{b9} Support Vector Machines, ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/svm.html}. [Accessed: Nov. 30, 2025].
    \bibitem{b10} Principal Component Analysis (PCA), ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/decomposition.html#pca}. [Accessed: Dec. 02, 2025].
    \bibitem{b11} Decision Trees , ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/modules/tree.html}. [Accessed: Nov. 30, 2025].
    \bibitem{b12} XGBoostClassifier, ``XGBoost API Documentation,'' [Online]. Available: \url{https://xgboost.readthedocs.io/en/stable/}. [Accessed: Nov. 30, 2025].
    \bibitem{b13} metrics, ``sklearn API Documentation,'' [Online]. Available: \url{https://scikit-learn.org/stable/api/sklearn.metrics.html}. [Accessed: Dec. 02, 2025].
\end{thebibliography}
\vspace{12pt}

\end{document}